{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0611 21:37:04.339408 18928 deprecation_wrapper.py:119] From F:\\Github\\DeepLearningForLandUseLandCoverClassification\\train.py:29: The name tf.keras.layers.CuDNNGRU is deprecated. Please use tf.compat.v1.keras.layers.CuDNNGRU instead.\n",
      "\n",
      "W0611 21:37:04.341620 18928 deprecation_wrapper.py:119] From F:\\Github\\DeepLearningForLandUseLandCoverClassification\\train.py:29: The name tf.keras.layers.CuDNNLSTM is deprecated. Please use tf.compat.v1.keras.layers.CuDNNLSTM instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import utils\n",
    "import train\n",
    "import predict\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from osgeo import gdal\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath1 = './'\n",
    "# ipath = []\n",
    "# cpath = []\n",
    "# size = 256\n",
    "# #List of all jps and tif files\n",
    "# ipath.append(\"./image2.tif\")\n",
    "# cpath.append(\"./label2.tif\")\n",
    "\n",
    "# img_id,tile_id,y_coord,x_coord = train.fetch_tiles_info(ipath)\n",
    "# img_id,tile_id,y_coord,x_coord = utils.shuffle_list(img_id,tile_id,y_coord,x_coord)\n",
    "\n",
    "# img_id_train,img_id_val,tile_id_train,tile_id_val,y_coord_train,y_coord_val,x_coord_train,x_coord_val = train_test_split(img_id,tile_id,y_coord,x_coord, train_size = 0.6, random_state=64, shuffle = True)\n",
    "# img_id_dev,img_id_test,tile_id_dev,tile_id_test,y_coord_dev,y_coord_test,x_coord_dev,x_coord_test = train_test_split(img_id_val,tile_id_val,y_coord_val,x_coord_val, train_size = 0.5, random_state=128, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 0, number of tiles: 441\n",
      "image: 1, number of tiles: 441\n",
      "image: 0, number of tiles: 441\n",
      "image: 0, number of tiles: 441\n"
     ]
    }
   ],
   "source": [
    "ipath_train = utils.get_all_images(\"./images/train/img\", \"tif\")\n",
    "cpath_train = utils.get_all_images(\"./images/train/mask\", \"tif\")\n",
    "ipath_dev = utils.get_all_images(\"./images/dev/img\", \"tif\")\n",
    "cpath_dev = utils.get_all_images(\"./images/dev/mask\", \"tif\")\n",
    "ipath_test = utils.get_all_images(\"./images/test/img\", \"tif\")\n",
    "cpath_test = utils.get_all_images(\"./images/test/mask\", \"tif\")\n",
    "\n",
    "\n",
    "img_id_train,tile_id_train,y_coord_train,x_coord_train = train.fetch_tiles_info(ipath_train)\n",
    "img_id_train,tile_id_train,y_coord_train,x_coord_train = utils.shuffle_list(img_id_train,tile_id_train,y_coord_train,x_coord_train)\n",
    "\n",
    "img_id_dev,tile_id_dev,y_coord_dev,x_coord_dev = train.fetch_tiles_info(ipath_dev)\n",
    "img_id_dev,tile_id_dev,y_coord_dev,x_coord_dev = utils.shuffle_list(img_id_dev,tile_id_dev,y_coord_dev,x_coord_dev)\n",
    "\n",
    "img_id_test,tile_id_test,y_coord_test,x_coord_test = train.fetch_tiles_info(ipath_test)\n",
    "img_id_test,tile_id_test,y_coord_test,x_coord_test = utils.shuffle_list(img_id_test,tile_id_test,y_coord_test,x_coord_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\keras_preprocessing\\image.py:1643: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (64, 256, 256, 6) (6 channels).\n",
      "  str(self.x.shape[channels_axis]) + ' channels).')\n",
      "c:\\python36\\lib\\site-packages\\keras_preprocessing\\image.py:1643: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (32, 256, 256, 6) (6 channels).\n",
      "  str(self.x.shape[channels_axis]) + ' channels).')\n"
     ]
    }
   ],
   "source": [
    "batch = 64\n",
    "val_batch = 32\n",
    "\n",
    "size = 256\n",
    "seed =140\n",
    "epoch =100\n",
    "lri = 1e-4\n",
    "steps_train = len(img_id_train)//batch\n",
    "steps_val = len(img_id_dev)//val_batch\n",
    "\n",
    "train_generator = train.msk_generator(ipath_train,cpath_train,img_id_train,tile_id_train,y_coord_train,x_coord_train, batch)\n",
    "val_generator = train.msk_generator(ipath_dev,cpath_dev,img_id_dev,tile_id_dev,y_coord_dev,x_coord_dev, val_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0611 21:37:11.596962 18928 callbacks.py:875] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 6) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 64) 3520        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 36928       conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 64) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 147584      conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  590080      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  2359808     conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 512)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 1024) 4719616     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 9438208     conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 16, 1024) 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 32, 32, 1024) 0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 1024) 0           dropout[0][0]                    \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 512)  2359808     conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 512)  0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 256)  590080      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 256 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 256 0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 128 295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 128 147584      conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 128 0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 128 0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 64) 36928       conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 4)  260         conv2d_21[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 31,033,668\n",
      "Trainable params: 31,033,668\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0611 21:37:13.441872 18928 deprecation.py:323] From c:\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.00000, saving model to ./model_1.h5\n",
      "41/41 - 80s - loss: 4.0000 - mean_io_u: 1.0000 - dice: 2.4414e-10 - val_loss: 4.0000 - val_mean_io_u: 1.0000 - val_dice: 2.4414e-10\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 4.00000\n",
      "41/41 - 58s - loss: 4.0264 - mean_io_u: 0.4970 - dice: 0.0121 - val_loss: 4.0242 - val_mean_io_u: 0.4954 - val_dice: 0.0251\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 4.00000\n",
      "41/41 - 59s - loss: 4.0000 - mean_io_u: 1.0000 - dice: 2.4414e-10 - val_loss: 4.0237 - val_mean_io_u: 0.4954 - val_dice: 0.0253\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 4.00000\n",
      "41/41 - 59s - loss: 4.0147 - mean_io_u: 0.4970 - dice: 0.0152 - val_loss: 4.0183 - val_mean_io_u: 0.4907 - val_dice: 0.0595\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 4.00000\n",
      "41/41 - 59s - loss: 4.0026 - mean_io_u: 0.4970 - dice: 0.0189 - val_loss: 4.0063 - val_mean_io_u: 0.4954 - val_dice: 0.0327\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 00006: val_loss improved from 4.00000 to 3.99231, saving model to ./model_1.h5\n",
      "41/41 - 61s - loss: 3.9956 - mean_io_u: 0.4970 - dice: 0.0229 - val_loss: 3.9923 - val_mean_io_u: 0.4954 - val_dice: 0.0356\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 00007: val_loss improved from 3.99231 to 3.99226, saving model to ./model_1.h5\n",
      "41/41 - 61s - loss: 4.0000 - mean_io_u: 1.0000 - dice: 2.4415e-10 - val_loss: 3.9923 - val_mean_io_u: 0.4954 - val_dice: 0.0356\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.99226\n",
      "41/41 - 59s - loss: 3.9879 - mean_io_u: 0.4970 - dice: 0.0241 - val_loss: 4.0085 - val_mean_io_u: 0.4907 - val_dice: 0.0703\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.99226\n",
      "41/41 - 59s - loss: 3.9974 - mean_io_u: 0.4970 - dice: 0.0244 - val_loss: 3.9961 - val_mean_io_u: 0.4954 - val_dice: 0.0344\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 00010: val_loss improved from 3.99226 to 3.99021, saving model to ./model_1.h5\n",
      "41/41 - 62s - loss: 3.9978 - mean_io_u: 0.4970 - dice: 0.0205 - val_loss: 3.9902 - val_mean_io_u: 0.4954 - val_dice: 0.0368\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 00011: val_loss improved from 3.99021 to 3.98979, saving model to ./model_1.h5\n",
      "41/41 - 61s - loss: 3.9871 - mean_io_u: 0.4970 - dice: 0.0249 - val_loss: 3.9898 - val_mean_io_u: 0.4954 - val_dice: 0.0369\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.98979\n",
      "41/41 - 60s - loss: 4.0000 - mean_io_u: 1.0000 - dice: 2.4415e-10 - val_loss: 3.9898 - val_mean_io_u: 0.4954 - val_dice: 0.0365\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.98979\n",
      "41/41 - 60s - loss: 4.0000 - mean_io_u: 1.0000 - dice: 2.4415e-10 - val_loss: 3.9899 - val_mean_io_u: 0.4954 - val_dice: 0.0365\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 00014: val_loss improved from 3.98979 to 3.98732, saving model to ./model_1.h5\n",
      "41/41 - 61s - loss: 3.9880 - mean_io_u: 0.4970 - dice: 0.0239 - val_loss: 3.9873 - val_mean_io_u: 0.4954 - val_dice: 0.0376\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 00015: val_loss improved from 3.98732 to 3.97156, saving model to ./model_1.h5\n",
      "41/41 - 61s - loss: 3.9877 - mean_io_u: 0.4970 - dice: 0.0250 - val_loss: 3.9716 - val_mean_io_u: 0.4907 - val_dice: 0.0764\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8c968f391310>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps_val\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlri\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\api\\_v1\\keras\\layers\\__init__.py\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(train_generator, val_generator, steps_train, steps_val, lri, epoch, size, seed)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[0mearly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    671\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m           \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m           initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m    674\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager_dataset_or_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m       \u001b[1;31m# Make sure that y, sample_weights, validation_split are not passed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1431\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1173\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train.training(train_generator,val_generator,steps_train,steps_val,lri,epoch,size,seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "tr_generator = train.msk_generator(ipath_train,cpath_train,img_id_train,tile_id_train,y_coord_train,x_coord_train, val_batch)\n",
    "vl_generator = train.msk_generator(ipath_dev,cpath_dev,img_id_dev,tile_id_dev,y_coord_dev,x_coord_dev, val_batch)\n",
    "test_generator = train.msk_generator(ipath_test,cpath_test,img_id_test,tile_id_test,y_coord_test,x_coord_test, val_batch)\n",
    "model = train.unet(size, lri)\n",
    "model.load_weights(\"./model_1.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Metrics: ', model.metrics_names)  \n",
    "l,iou,dice = model.evaluate(train_generator, verbose=1, steps=len(x_coord_train)//(val_batch))\n",
    "\n",
    "l,iou,dice = model.evaluate(val_generator, verbose=1, steps=len(x_coord_dev)//(val_batch))\n",
    "\n",
    "l,iou,dice = model.evaluate(test_generator, verbose=1, steps=len(x_coord_test)//(val_batch))\n",
    "\n",
    "   \n",
    "K.clear_session()\n",
    "del model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "folder = \"./images/test/img\"\n",
    "mpath = \"./model_1.h5\"\n",
    "model = train.unet(size, lri)\n",
    "model.load_weights(mpath)\n",
    "\n",
    "flist = utils.get_all_images(folder, \"tif\")\n",
    "predict.predict_all_images(flist,model,val_batch//2,True)\n",
    "\n",
    "K.clear_session()\n",
    "del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = cv.imread(\"./predictions/prediction_1.tif\",-1)\n",
    "print(pred.shape)\n",
    "plt.imshow(pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = np.expand_dims(pred,axis =-1)\n",
    "pred1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in set(pred.ravel()):\n",
    "    print(\"class: {}, count: {}\".format(s,np.sum(pred[pred==s])//s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "pred1 = to_categorical(pred,4)\n",
    "pred1[:,:,0] +=pred1[:,:,-1]\n",
    "pred1[:,:,1] +=pred1[:,:,-1]\n",
    "pred1 = 255 * pred1[:,:,:-1]\n",
    "pred1 = cv.cvtColor(pred1, cv.COLOR_RGB2BGR)\n",
    "cv.imwrite(\"./prediction_1-rgb.tif\",pred1.astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_bgr = cv.imread(\"./prediction_1-rgb.tif\")\n",
    "pred_rgb = cv.cvtColor(pred_bgr, cv.COLOR_BGR2RGB)\n",
    "plt.imshow(pred_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
