{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fi4TowLVzHUA"
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "\n",
    "import h5py\n",
    "import random\n",
    "from scipy import ndarray\n",
    "from skimage import exposure\n",
    "from random import random as rd\n",
    "import cv2 as cv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator \n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.losses import binary_crossentropy as bce\n",
    "from keras.losses import categorical_crossentropy as cce\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping \n",
    "from keras.utils.np_utils import to_categorical   \n",
    "# from h2o4gpu.solvers.kmeans import KMeans as kmeans\n",
    "from sklearn.cluster import KMeans as kmeans\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fGiIgSdzkMn"
   },
   "outputs": [],
   "source": [
    "def img_generator(image_path,image_id,tile_id,y_coord,x_coord,batch):\n",
    "    \n",
    "    \n",
    "    def com_gen(image,label):\n",
    "        K.set_image_data_format('channels_last')\n",
    "        def combine_generator(gen1, gen2):\n",
    "            while True:\n",
    "                yield(gen1.next(), gen2.next())\n",
    "        \n",
    "        data_gen_args = dict(horizontal_flip=True,\n",
    "                         vertical_flip=True,\n",
    "                         rotation_range=45,\n",
    "                         width_shift_range=0.2,\n",
    "                         height_shift_range=0.2,\n",
    "                         #brightness_range=[0.8,1.2],\n",
    "                         #shear_range=0.2,\n",
    "                         #channel_shift_range = 20,\n",
    "                         zoom_range=0.2,\n",
    "                         fill_mode='nearest',\n",
    "                         data_format = \"channels_last\",\n",
    "                         rescale = 1./255)\n",
    "        \n",
    "        image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "        mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "        #image_datagen.fit(image, augment=True, rounds=1, seed=42)\n",
    "        #mask_datagen.fit(label, augment=True, rounds=1, seed=42)\n",
    "        image_generator = image_datagen.flow(image, batch_size=1, seed=42)\n",
    "        mask_generator = mask_datagen.flow(label, batch_size=1, seed=42)\n",
    "        train_generator = combine_generator(image_generator,mask_generator)\n",
    "        return train_generator\n",
    "\n",
    "    \n",
    "    total_images = len(y_coord)\n",
    "    all_images_id =list(range(total_images))\n",
    "    random.seed(948)\n",
    "    random.shuffle(all_images_id)\n",
    "    \n",
    "    current_image_id = 0\n",
    "    while (current_image_id<total_images):\n",
    "        \n",
    "        random.shuffle(all_images_id)\n",
    "        \n",
    "        batch_input = np.zeros((batch,size,size,6))\n",
    "        batch_output = np.zeros((batch,size,size,10))\n",
    "        \n",
    "       \n",
    "        for batch_index in range(batch):\n",
    "            index = all_images_id[current_image_id]\n",
    "            x = x_coord[index]\n",
    "            y = y_coord[index]\n",
    "            img_id = image_id[index]\n",
    "            \n",
    "        \n",
    "            raster = gdal.Open(image_path[img_id])\n",
    "            img = utils.raster2arr(raster,4,x,y,size)\n",
    "            raster = None\n",
    "            batch_input[m,:,:,:],ndvi,ndwi = utils.add_veg_water_index(img)\n",
    "            clt = utils.generate_labels(batch_input[m,:,:,:],ndvi,ndwi)\n",
    "            \n",
    "            batch_output[m,:,:,:] = (to_categorical(clt,num_classes=10))*255.0\n",
    "            del img,clt\n",
    "            \n",
    "        current_image_id += 1\n",
    "        return (com_gen(batch_input, batch_output))\n",
    "    \n",
    "def msk_generator(image_path,image_id,tile_id,y_coord,x_coord,batch):    \n",
    "    \n",
    "    \n",
    "    def com_gen(image2,label2):\n",
    "        K.set_image_data_format('channels_last')\n",
    "        def combine_generator(gen1, gen2):\n",
    "            while True:\n",
    "                yield(gen1.next(), gen2.next())                                   \n",
    "  \n",
    "        data_gen_args2 = dict(data_format = \"channels_last\",\n",
    "                             rescale = 1./255)\n",
    "        image_datagen2 = ImageDataGenerator(**data_gen_args2)\n",
    "        mask_datagen2 = ImageDataGenerator(**data_gen_args2)\n",
    "        #image_datagen.fit(image, augment=True, rounds=5, seed=42)\n",
    "        #mask_datagen.fit(label, augment=True, rounds=5, seed=42)\n",
    "        image_generator2 = image_datagen2.flow(image2, batch_size=1, seed=56)\n",
    "        mask_generator2 = mask_datagen2.flow(label2, batch_size=1, seed=56)\n",
    "        val_generator = combine_generator(image_generator2,mask_generator2)\n",
    "        return val_generator\n",
    "    \n",
    "    total_images = len(y_coord)\n",
    "    all_images_id =list(range(total_images))\n",
    "    random.seed(948)\n",
    "    random.shuffle(all_images_id)\n",
    "    \n",
    "    current_image_id = 0\n",
    "    while (current_image_id<total_images):\n",
    "        \n",
    "        random.shuffle(all_images_id)\n",
    "        \n",
    "        batch_input = np.zeros((batch,size,size,6))\n",
    "        batch_output = np.zeros((batch,size,size,10))\n",
    "        \n",
    "        \n",
    "        for batch_index in range(batch):\n",
    "            index = all_images_id[current_image_id]\n",
    "            x = x_coord[index]\n",
    "            y = y_coord[index]\n",
    "            img_id = image_id[index]\n",
    "            \n",
    "        \n",
    "            raster = gdal.Open(image_path[img_id])\n",
    "\n",
    "            img = raster2arr(raster,4,x,y,size)\n",
    "            raster = None           \n",
    "            batch_inputm[m,:,:,:],ndvi,ndwi = util.add_veg_water_index(img)\n",
    "            clt = util.generate_labels(batch_inputm[m,:,:,:],ndvi,ndwi)\n",
    "        \n",
    "            batch_outputm[m,:,:,:] = (to_categorical(clt,num_classes=10))*255.0  \n",
    "            del img,clt\n",
    "    \n",
    "        current_image_id += 1\n",
    "        return (com_gen(batch_inputm, batch_outputm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ePUbRJ3KzuAa"
   },
   "outputs": [],
   "source": [
    "size = 256\n",
    "def unet(size, lri, input_height = size, input_width = size, nClasses = 10):\n",
    "\n",
    "    K.set_image_data_format('channels_last')\n",
    "    \n",
    "    input_size = (input_width, input_height, 6)\n",
    "    input1 = Input(shape = input_size)\n",
    "    n = 64\n",
    "    drate1 = 0\n",
    "    drate2 = 0\n",
    "    drate3 = 0\n",
    "    drate4 = 0\n",
    "    drate5 = 0\n",
    "    lmbd = 0\n",
    "    #bn01 = ( BatchNormalization())(input1) \n",
    "    \n",
    "    #drop0 = Dropout(0)(input1)\n",
    "    conv1 = Conv2D(n, (3,3), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same', data_format= \"channels_last\", kernel_initializer = 'he_normal')(input1)\n",
    "    drop1 = Dropout(drate1)(conv1)\n",
    "    bn11 = ( BatchNormalization())(drop1) \n",
    "\n",
    "    conv1 = Conv2D(n, (3,3), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same', data_format= \"channels_last\", kernel_initializer = 'he_normal')(bn11)\n",
    "    drop12 = Dropout(drate2)(conv1)\n",
    "    bn12 = ( BatchNormalization())(drop12) \n",
    "\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(bn12)\n",
    "    \n",
    "    conv2 = Conv2D(n*2, (3,3), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same',  data_format= \"channels_last\", kernel_initializer = 'he_normal')(pool1)\n",
    "    drop2 = Dropout(drate1)(conv2) \n",
    "    bn21 = ( BatchNormalization())(drop2)\n",
    "\n",
    "    conv2 = Conv2D(n*2, (3,3), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same',  data_format= \"channels_last\", kernel_initializer = 'he_normal')(bn21)\n",
    "    drop22 = Dropout(drate2)(conv2)  \n",
    "    bn22 = ( BatchNormalization())(drop22)   \n",
    "    \n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(bn22)\n",
    "    \n",
    "    conv3 = Conv2D(n*4, (3,3), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same', data_format= \"channels_last\", kernel_initializer = 'he_normal')(pool2)\n",
    "    drop3 = Dropout(drate1)(conv3)\n",
    "    bn31 = ( BatchNormalization())(drop3)\n",
    "\n",
    "    conv3 = Conv2D(n*4, (3,3), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same', data_format= \"channels_last\", kernel_initializer ='he_normal')(bn31)\n",
    "    drop32 = Dropout(drate2)(conv3)\n",
    "    bn32 = ( BatchNormalization())(drop32) \n",
    "    \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(bn32)\n",
    "    \n",
    "    conv4 = Conv2D(n*8, (3,3), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same', data_format= \"channels_last\", kernel_initializer ='he_normal')(pool3)\n",
    "    drop4 = Dropout(drate1)(conv4)\n",
    "    bn41 = ( BatchNormalization())(drop4) \n",
    "\n",
    "    conv4 = Conv2D(n*8, (3,3), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same', data_format= \"channels_last\", kernel_initializer ='he_normal')(bn41)\n",
    "    drop42 = Dropout(drate5)(conv4)\n",
    "    bn42 = ( BatchNormalization())(drop42) \n",
    "    \n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(bn42)\n",
    "   \n",
    "    conv5 = Conv2D(n*16, (3,3), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same', data_format= \"channels_last\", kernel_initializer ='he_normal')(pool4)\n",
    "    drop5 = Dropout(drate5)(conv5)\n",
    "    bn51 = ( BatchNormalization())(drop5) \n",
    "    conv5 = Conv2D(n*16, (3,3), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same', data_format= \"channels_last\", kernel_initializer ='he_normal')(bn51)\n",
    "    drop52 = Dropout(drate4)(conv5)\n",
    "    bn52 = ( BatchNormalization())(drop52) \n",
    "    \n",
    "    up6 = Conv2D(n*8, (2,2), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same',data_format= \"channels_last\",  kernel_initializer ='he_normal')(UpSampling2D(size = (2,2))(bn52))\n",
    "    merge6 = concatenate([bn42,up6], axis = 3)\n",
    "    #merge6 = concatenate([conv4,up6], axis = 3)\n",
    "    \n",
    "    conv6 = Conv2D(n*8, (3,3), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same', data_format= \"channels_last\", kernel_initializer ='he_normal')(merge6)\n",
    "    drop6 = Dropout(drate3)(conv6)\n",
    "    bn61 = ( BatchNormalization())(drop6) \n",
    "\n",
    "    conv6 = Conv2D(n*8, (3,3), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same', data_format= \"channels_last\", kernel_initializer ='he_normal')(bn61)\n",
    "    drop62 = Dropout(drate4)(conv6)\n",
    "    bn62 = ( BatchNormalization())(drop62) \n",
    "    \n",
    "    up7 = Conv2D(n*4, (2,2), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same', data_format= \"channels_last\", kernel_initializer ='he_normal')(UpSampling2D(size = (2,2))(bn62))\n",
    "    \n",
    "    merge7 = concatenate([bn32,up7], axis = 3)\n",
    "    \n",
    "    \n",
    "    conv7 = Conv2D(n*4, (3,3), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same', data_format= \"channels_last\", kernel_initializer ='he_normal')(merge7)\n",
    "    drop7 = Dropout(drate3)(conv7)\n",
    "    bn71 = ( BatchNormalization())(drop7) \n",
    "\n",
    "    conv7 = Conv2D(n*4, (3,3), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same', data_format= \"channels_last\", kernel_initializer ='he_normal')(bn71)\n",
    "    drop72 = Dropout(drate4)(conv7)\n",
    "    bn72 = ( BatchNormalization())(drop72) \n",
    "    \n",
    "\n",
    "    up8 = Conv2D(n*2, (2,2), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same', data_format= \"channels_last\", kernel_initializer ='he_normal')(UpSampling2D(size = (2,2))(bn72))\n",
    "    \n",
    "    \n",
    "    merge8 = concatenate([bn22,up8], axis = 3)\n",
    "    \n",
    "    conv8 = Conv2D(n*2, (3,3), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same', data_format= \"channels_last\", kernel_initializer ='he_normal')(merge8)\n",
    "    drop8 = Dropout(drate3)(conv8)\n",
    "    bn81 = ( BatchNormalization())(drop8) \n",
    "\n",
    "    conv8 = Conv2D(n*2, (3,3), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same', data_format= \"channels_last\", kernel_initializer ='he_normal')(bn81)\n",
    "    drop82 = Dropout(drate4)(conv8)\n",
    "    bn82 = ( BatchNormalization())(drop82) \n",
    "    \n",
    "    up9 = Conv2D(n, (2,2), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same', data_format= \"channels_last\", kernel_initializer ='he_normal')(UpSampling2D(size = (2,2))(bn82))\n",
    "    merge9 = concatenate([bn12,up9], axis = 3)\n",
    "    \n",
    "    conv9 = Conv2D(n, (3,3), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same', data_format= \"channels_last\", kernel_initializer ='he_normal')(merge9)\n",
    "    drop9 = Dropout(drate3)(conv9)\n",
    "    bn91 = ( BatchNormalization())(drop9) \n",
    "\n",
    "    conv9 = Conv2D(n, (3,3), kernel_regularizer=l2(lmbd), activation = 'relu', padding = 'same', data_format= \"channels_last\", kernel_initializer ='he_normal')(bn91)\n",
    "    drop92 = Dropout(drate4)(conv9)\n",
    "    bn92 = ( BatchNormalization())(drop92) \n",
    "    \n",
    "    conv10 = Conv2D(nClasses, (1,1), kernel_regularizer=l2(lmbd), activation = 'softmax', padding = 'same', data_format= \"channels_last\", kernel_initializer ='he_normal')(bn92)\n",
    "    model = Model(inputs = input1, outputs = conv10)\n",
    "    \n",
    "    model.compile(optimizer = Adam(lr  = lri), loss= utils.dice_loss, metrics = [utils.iou, utils.dice])\n",
    "   \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "v2UvXO4L0C-Q",
    "outputId": "0ea186d3-d8d4-4efd-d7cf-dad630d21efa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7561 7694\n",
      "29 30 870\n",
      "(29,)\n",
      "(30,)\n",
      "idj:  870\n",
      "ar1:  870\n",
      "ar2:  870\n",
      "10980 7694\n",
      "42 30 1260\n",
      "(42,)\n",
      "(30,)\n",
      "idj:  1260\n",
      "ar1:  1260\n",
      "ar2:  1260\n",
      "10980 7694\n",
      "42 30 1260\n",
      "(42,)\n",
      "(30,)\n",
      "idj:  1260\n",
      "ar1:  1260\n",
      "ar2:  1260\n",
      "7561 10980\n",
      "29 42 1218\n",
      "(29,)\n",
      "(42,)\n",
      "idj:  1218\n",
      "ar1:  1218\n",
      "ar2:  1218\n",
      "10980 10980\n",
      "42 42 1764\n",
      "(42,)\n",
      "(42,)\n",
      "idj:  1764\n",
      "ar1:  1764\n",
      "ar2:  1764\n",
      "10980 10980\n",
      "42 42 1764\n",
      "(42,)\n",
      "(42,)\n",
      "idj:  1764\n",
      "ar1:  1764\n",
      "ar2:  1764\n",
      "10980 10980\n",
      "42 42 1764\n",
      "(42,)\n",
      "(42,)\n",
      "idj:  1764\n",
      "ar1:  1764\n",
      "ar2:  1764\n",
      "10980 10980\n",
      "42 42 1764\n",
      "(42,)\n",
      "(42,)\n",
      "idj:  1764\n",
      "ar1:  1764\n",
      "ar2:  1764\n",
      "10980 10980\n",
      "42 42 1764\n",
      "(42,)\n",
      "(42,)\n",
      "idj:  1764\n",
      "ar1:  1764\n",
      "ar2:  1764\n",
      "10980 10980\n",
      "42 42 1764\n",
      "(42,)\n",
      "(42,)\n",
      "idj:  1764\n",
      "ar1:  1764\n",
      "ar2:  1764\n",
      "10980 10980\n",
      "42 42 1764\n",
      "(42,)\n",
      "(42,)\n",
      "idj:  1764\n",
      "ar1:  1764\n",
      "ar2:  1764\n",
      "10980 10980\n",
      "42 42 1764\n",
      "(42,)\n",
      "(42,)\n",
      "idj:  1764\n",
      "ar1:  1764\n",
      "ar2:  1764\n",
      "10980 10980\n",
      "42 42 1764\n",
      "(42,)\n",
      "(42,)\n",
      "idj:  1764\n",
      "ar1:  1764\n",
      "ar2:  1764\n",
      "10980 10980\n",
      "42 42 1764\n",
      "(42,)\n",
      "(42,)\n",
      "idj:  1764\n",
      "ar1:  1764\n",
      "ar2:  1764\n",
      "10980 10980\n",
      "42 42 1764\n",
      "(42,)\n",
      "(42,)\n",
      "idj:  1764\n",
      "ar1:  1764\n",
      "ar2:  1764\n",
      "10980 10980\n",
      "42 42 1764\n",
      "(42,)\n",
      "(42,)\n",
      "idj:  1764\n",
      "ar1:  1764\n",
      "ar2:  1764\n",
      "10980 10980\n",
      "42 42 1764\n",
      "(42,)\n",
      "(42,)\n",
      "idj:  1764\n",
      "ar1:  1764\n",
      "ar2:  1764\n",
      "10980 10980\n",
      "42 42 1764\n",
      "(42,)\n",
      "(42,)\n",
      "idj:  1764\n",
      "ar1:  1764\n",
      "ar2:  1764\n",
      "10980 10980\n",
      "42 42 1764\n",
      "(42,)\n",
      "(42,)\n",
      "idj:  1764\n",
      "ar1:  1764\n",
      "ar2:  1764\n",
      "10980 10980\n",
      "42 42 1764\n",
      "(42,)\n",
      "(42,)\n",
      "idj:  1764\n",
      "ar1:  1764\n",
      "ar2:  1764\n",
      "10980 10980\n",
      "42 42 1764\n",
      "(42,)\n",
      "(42,)\n",
      "idj:  1764\n",
      "ar1:  1764\n",
      "ar2:  1764\n",
      "10980 10980\n",
      "42 42 1764\n",
      "(42,)\n",
      "(42,)\n",
      "idj:  1764\n",
      "ar1:  1764\n",
      "ar2:  1764\n",
      "10980 4161\n",
      "42 16 672\n",
      "(42,)\n",
      "(16,)\n",
      "idj:  672\n",
      "ar1:  672\n",
      "ar2:  672\n"
     ]
    }
   ],
   "source": [
    "def fetch_tiles_info(ipath):\n",
    "    img_id  = []\n",
    "    tile_id = []\n",
    "    y_coord = []\n",
    "    x_coord = []\n",
    "\n",
    "\n",
    "    for i in range(len(ipath)):\n",
    "        img_id,tile_id,y_coord,x_coord = utils.apply_fetch_all_tiles(ipath[i],img_id,tile_id,y_coord,x_coord,1,i)\n",
    "        \n",
    "        img_id,tile_id,y_coord,x_coord = utils.apply_fetch_tiles_at_random(ipath[i],img_id,tile_id,y_coord,x_coord,len(img_id),len(img_id),i)\n",
    "    \n",
    "    return img_id,tile_id,y_coord,x_coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "id": "f49huDX00eW4",
    "outputId": "1fa95883-a1f0-4381-d240-3467b5f7cb7f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/numpy_array_iterator.py:136: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (128, 256, 256, 6) (6 channels).\n",
      "  str(self.x.shape[channels_axis]) + ' channels).')\n",
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/numpy_array_iterator.py:136: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (128, 256, 256, 10) (10 channels).\n",
      "  str(self.x.shape[channels_axis]) + ' channels).')\n",
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/numpy_array_iterator.py:136: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (32, 256, 256, 6) (6 channels).\n",
      "  str(self.x.shape[channels_axis]) + ' channels).')\n",
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/numpy_array_iterator.py:136: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (32, 256, 256, 10) (10 channels).\n",
      "  str(self.x.shape[channels_axis]) + ' channels).')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PulM8cH60hx_",
    "outputId": "bd394f30-9783-4ee6-d2b8-86837f9536d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 6) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 64) 3520        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 256, 256, 64) 0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 256, 256, 64) 256         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 36928       batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256, 256, 64) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256, 256, 64) 256         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 128 73856       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128, 128, 128 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 128 512         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 147584      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128, 128, 128 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 128, 128, 128 512         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 256)  295168      max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 64, 64, 256)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 256)  1024        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  590080      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 64, 64, 256)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 256)  1024        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 512)  1180160     max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 512)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 512)  2048        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  2359808     batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 512)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 512)  2048        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 1024) 4719616     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 16, 16, 1024) 0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 16, 1024) 4096        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 9438208     batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16, 16, 1024) 0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 1024) 4096        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 32, 32, 1024) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 512)  2097664     up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 1024) 0           batch_normalization_7[0][0]      \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 512)  4719104     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 32, 512)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 512)  2048        dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 512)  2359808     batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 512)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 512)  2048        dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 512)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 256)  524544      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 512)  0           batch_normalization_5[0][0]      \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 256)  1179904     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 64, 64, 256)  0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 256)  1024        dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 64, 64, 256)  590080      batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 64, 64, 256)  0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 256)  1024        dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 256 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 128 131200      up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 256 0           batch_normalization_3[0][0]      \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 128, 128, 128 295040      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 128, 128, 128 0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128, 128, 128 512         dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 128, 128, 128 147584      batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 128, 128, 128 0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128, 128, 128 512         dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 128 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 64) 32832       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 128 0           batch_normalization_1[0][0]      \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 256, 256, 64) 73792       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 256, 256, 64) 0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 256, 256, 64) 256         dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 256, 256, 64) 36928       batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 256, 256, 64) 0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 256, 256, 64) 256         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 10) 650         batch_normalization_17[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 31,057,610\n",
      "Trainable params: 31,045,834\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "WARNING:tensorflow:From <ipython-input-16-f0fbf32e7b46>:19: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/1000\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0403s vs `on_train_batch_end` time: 0.0645s). Check your callbacks.\n",
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0063s vs `on_test_batch_end` time: 0.0183s). Check your callbacks.\n",
      "\n",
      "Epoch 00001: val_dice improved from -inf to 5.59934, saving model to /content/drive/My Drive/Excel/vietnam_unsup2-4.h5\n",
      "260/260 - 33s - loss: 1.0147 - iou: 7.9708 - dice: 7.9852 - val_loss: 3.4007 - val_iou: 5.5652 - val_dice: 5.5993\n",
      "Epoch 2/1000\n",
      "\n",
      "Epoch 00002: val_dice improved from 5.59934 to 5.71402, saving model to /content/drive/My Drive/Excel/vietnam_unsup2-4.h5\n",
      "260/260 - 34s - loss: 1.0147 - iou: 7.9708 - dice: 7.9852 - val_loss: 3.2860 - val_iou: 5.6833 - val_dice: 5.7140\n",
      "Epoch 3/1000\n",
      "\n",
      "Epoch 00003: val_dice improved from 5.71402 to 5.75925, saving model to /content/drive/My Drive/Excel/vietnam_unsup2-4.h5\n",
      "260/260 - 34s - loss: 1.0147 - iou: 7.9708 - dice: 7.9852 - val_loss: 3.2407 - val_iou: 5.7319 - val_dice: 5.7593\n",
      "Epoch 4/1000\n",
      "\n",
      "Epoch 00004: val_dice did not improve from 5.75925\n",
      "260/260 - 31s - loss: 1.0147 - iou: 7.9708 - dice: 7.9852 - val_loss: 3.3211 - val_iou: 5.6482 - val_dice: 5.6789\n",
      "Epoch 5/1000\n",
      "\n",
      "Epoch 00005: val_dice did not improve from 5.75925\n",
      "260/260 - 31s - loss: 1.0147 - iou: 7.9708 - dice: 7.9852 - val_loss: 3.4189 - val_iou: 5.5469 - val_dice: 5.5811\n",
      "Epoch 6/1000\n",
      "\n",
      "Epoch 00006: val_dice improved from 5.75925 to 5.97325, saving model to /content/drive/My Drive/Excel/vietnam_unsup2-4.h5\n",
      "260/260 - 33s - loss: 1.0147 - iou: 7.9708 - dice: 7.9852 - val_loss: 3.0268 - val_iou: 5.9528 - val_dice: 5.9732\n",
      "Epoch 7/1000\n",
      "\n",
      "Epoch 00007: val_dice did not improve from 5.97325\n",
      "260/260 - 30s - loss: 1.0147 - iou: 7.9708 - dice: 7.9852 - val_loss: 3.3386 - val_iou: 5.6307 - val_dice: 5.6614\n",
      "Epoch 8/1000\n",
      "\n",
      "Epoch 00008: val_dice did not improve from 5.97325\n",
      "260/260 - 30s - loss: 1.0147 - iou: 7.9708 - dice: 7.9852 - val_loss: 3.4992 - val_iou: 5.4632 - val_dice: 5.5008\n",
      "Epoch 9/1000\n",
      "\n",
      "Epoch 00009: val_dice did not improve from 5.97325\n",
      "260/260 - 30s - loss: 1.0147 - iou: 7.9708 - dice: 7.9852 - val_loss: 3.2232 - val_iou: 5.7495 - val_dice: 5.7768\n",
      "Epoch 10/1000\n",
      "\n",
      "Epoch 00010: val_dice did not improve from 5.97325\n",
      "260/260 - 30s - loss: 1.0147 - iou: 7.9708 - dice: 7.9852 - val_loss: 3.3035 - val_iou: 5.6657 - val_dice: 5.6965\n",
      "Epoch 11/1000\n",
      "\n",
      "Epoch 00011: val_dice did not improve from 5.97325\n",
      "260/260 - 30s - loss: 1.0147 - iou: 7.9708 - dice: 7.9852 - val_loss: 3.1429 - val_iou: 5.8332 - val_dice: 5.8571\n",
      "Epoch 12/1000\n",
      "\n",
      "Epoch 00012: val_dice did not improve from 5.97325\n",
      "260/260 - 30s - loss: 1.0147 - iou: 7.9708 - dice: 7.9852 - val_loss: 3.4634 - val_iou: 5.4990 - val_dice: 5.5366\n",
      "Epoch 13/1000\n",
      "\n",
      "Epoch 00013: val_dice did not improve from 5.97325\n",
      "260/260 - 30s - loss: 1.0147 - iou: 7.9708 - dice: 7.9852 - val_loss: 3.3386 - val_iou: 5.6307 - val_dice: 5.6614\n",
      "Epoch 14/1000\n",
      "\n",
      "Epoch 00014: val_dice did not improve from 5.97325\n",
      "260/260 - 30s - loss: 1.0147 - iou: 7.9708 - dice: 7.9852 - val_loss: 3.3386 - val_iou: 5.6307 - val_dice: 5.6614\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f0fbf32e7b46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-f0fbf32e7b46>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(size)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#tensorboard = TensorBoard(log_dir= logdir, histogram_freq=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mearly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_iou'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar1_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearly\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar1_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mval_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;31m#history = model.fit_generator(train_generator, steps_per_epoch = (len(train_X)/ batch), epochs =300 ,verbose = 2, callbacks = [tensorboard, checkpoint], validation_data= val_generator, validation_steps = (len(val_X)/4), shuffle =True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#for layer in model.layers[:6]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1827\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1828\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1829\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m   @deprecation.deprecated(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1101\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \"\"\"\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    307\u001b[0m       \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m           \u001b[0mnumpy_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 635\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    531\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \"\"\"\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1027\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1030\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def training(train_generator,val_generator,steps_train,steps_val,epoch =50,size=256,seed = 100):\n",
    "    K.clear_session()\n",
    "    model = 0\n",
    "    del model         \n",
    "    K.set_image_data_format('channels_last')\n",
    "    seed = 100\n",
    "    np.random.seed(seed)\n",
    "    tf.compat.v1.set_random_seed(seed)\n",
    "    lri = 1e-4\n",
    "\n",
    "    model = unet(size, lri)\n",
    "    model.summary()\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(\"./model_1.h5\", monitor='val_dice', verbose=1, save_best_only=True, save_weights_only=False, mode='max', period=1)\n",
    "    \n",
    "    early = EarlyStopping(monitor='val_iou', min_delta=0, patience=25, verbose=1, mode='auto')\n",
    "    history = model.fit(train_generator, steps_per_epoch = steps_train, epochs = epoch ,verbose = 2, callbacks = [checkpoint, early], validation_data= val_generator, validation_steps = steps_val)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vTOTygDIUMbk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train_multiclass_18-10-20.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
